{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL: Modelado de Niveles Freáticos con Pastas\n",
    "\n",
    "Este notebook demuestra cómo construir modelos de niveles freáticos usando la biblioteca Pastas, considerando múltiples factores de estrés (precipitación, evaporación, y bombeos).\n",
    "\n",
    "**Estructura:**\n",
    "1. Carga y preparación de datos de niveles\n",
    "2. Análisis de tendencias (Mann-Kendall)\n",
    "3. Carga y preparación de datos de estrés (clima y bombeos)\n",
    "4. Construcción de modelos Pastas con diferentes configuraciones\n",
    "5. Evaluación y exportación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports y configuración"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import pandas as pd\n",
    "import pastas as ps\n",
    "import matplotlib.pyplot as plt\n",
    "import pymannkendall as mk\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "ps.set_log_level(\"ERROR\")\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "# Multiprocessing: 1 = secuencial, >1 = paralelo por pozo (para cada modelo)\n",
    "N_WORKERS = 1  # ej. 4 o cpu_count() - 1 para acelerar"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_pumping_data(filepath: str) -> pd.Series:\n",
    "    \"\"\"Carga datos de bombeo mensuales y los convierte a serie diaria (m³/día, negativos).\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df[\"Fecha\"] = pd.to_datetime(df[\"Fecha\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "    df = df.dropna().set_index(\"Fecha\").sort_index()\n",
    "    if df.index.duplicated().any():\n",
    "        df = df.groupby(df.index).mean(numeric_only=True)\n",
    "    days_in_month = df.index.days_in_month\n",
    "    df[\"m3_day\"] = df[\"total\"] / days_in_month\n",
    "    daily_series = df[\"m3_day\"].resample(\"D\").ffill()\n",
    "    return -1 * daily_series\n",
    "\n",
    "\n",
    "def distancia_utm(este_1, norte_1, este_2, norte_2):\n",
    "    \"\"\"Distancia euclidiana entre dos puntos UTM (metros).\"\"\"\n",
    "    e1, n1 = np.asarray(este_1, dtype=float), np.asarray(norte_1, dtype=float)\n",
    "    e2, n2 = np.asarray(este_2, dtype=float), np.asarray(norte_2, dtype=float)\n",
    "    return np.hypot(e2 - e1, n2 - n1)\n",
    "\n",
    "\n",
    "def calculate_model_statistics(model: ps.Model) -> dict:\n",
    "    \"\"\"Estadísticas de validación del modelo (R², RMSE, tests sobre residuales).\"\"\"\n",
    "    residuals = model.residuals()\n",
    "    t_stat, p_value_t = stats.ttest_1samp(residuals, 0)\n",
    "    stat_wilc, p_value_wilc = stats.wilcoxon(residuals)\n",
    "    stat_shap, p_value_shap = stats.shapiro(residuals)\n",
    "    r2 = model.stats.rsq()\n",
    "    rmse = model.stats.rmse()\n",
    "    bic = model.stats.bic()\n",
    "    obs = model.oseries.series\n",
    "    sim = model.simulate()\n",
    "    std_obs = model.oseries.series.dropna().std()\n",
    "    mae = np.mean(np.abs(sim - obs))\n",
    "    return {\n",
    "        \"R²\": r2, \"RMSE\": rmse, \"std_obs07\": std_obs * 0.7,\n",
    "        \"p-value wilconox\": p_value_wilc, \"MAE\": mae, \"BIC\": bic, \"p-value shapiro\": p_value_shap,\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_ivm(row: pd.Series) -> str:\n",
    "    \"\"\"Indicador de Validación del Modelo: Válido si cumple R², RMSE, Wilcoxon, MAE.\"\"\"\n",
    "    try:\n",
    "        conditions = [\n",
    "            pd.notna(row[\"R²\"]) and row[\"R²\"] > 0.65,\n",
    "            pd.notna(row[\"RMSE\"]) and row[\"RMSE\"] < row[\"std_obs07\"],\n",
    "            pd.notna(row[\"p-value wilconox\"]) and row[\"p-value wilconox\"] > 0.05,\n",
    "            pd.notna(row[\"MAE\"]) and row[\"MAE\"] < row[\"std_obs07\"],\n",
    "        ]\n",
    "        return \"Válido\" if all(conditions) else \"No Válido\"\n",
    "    except (KeyError, TypeError):\n",
    "        return \"No Válido\"\n",
    "\n",
    "\n",
    "def _trunc3(x: float) -> float:\n",
    "    return float(np.trunc(float(x) * 1000.0) / 1000.0)\n",
    "\n",
    "\n",
    "def _mk_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Aplica Mann-Kendall a cada pozo; retorna tabla con Z, S, p-value, tendencia.\"\"\"\n",
    "    def _trend_es(t):\n",
    "        t = str(t).strip().lower()\n",
    "        if t == \"increasing\": return \"Creciente\"\n",
    "        if t == \"decreasing\": return \"Decreciente\"\n",
    "        return \"Sin tendencia\"\n",
    "    mk_results = []\n",
    "    for pozo, g in df.groupby(\"Pozo\", sort=True):\n",
    "        serie = g.sort_values(\"Fecha\")[\"Valor\"].dropna()\n",
    "        if len(serie) < 3:\n",
    "            continue\n",
    "        res = mk.original_test(serie)\n",
    "        mk_results.append({\"Pozo\": pozo, \"Estadistico Z\": _trunc3(res.z), \"Estadistico S\": int(res.s),\n",
    "                          \"p-value\": _trunc3(res.p), \"tendencia\": _trend_es(res.trend)})\n",
    "    return pd.DataFrame(mk_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Funciones para construir modelos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_data_bundle():\n",
    "    \"\"\"Agrupa datos necesarios para construir modelos (se usa en secuencial y paralelo).\"\"\"\n",
    "    return {\n",
    "        \"niveles_series\": niveles_series,\n",
    "        \"coordenadas_niveles\": coordenadas_niveles,\n",
    "        \"coordenadas_bombeos\": coordenadas_bombeos,\n",
    "        \"sm_precip\": sm_precip, \"sm_evap\": sm_evap,\n",
    "        \"ALB_series\": ALB_series, \"SOP_series\": SOP_series, \"MOP_series\": MOP_series,\n",
    "        \"TIL_series\": TIL_series, \"TUC_series\": TUC_series, \"PEINE_series\": PEINE_series,\n",
    "    }\n",
    "\n",
    "\n",
    "def create_model_with_data(modelo: str, location_names: list, data: dict):\n",
    "    \"\"\"Construye y calibra un modelo Pastas para cada pozo usando solo `data`. Returns (model_stats, gains_data).\"\"\"\n",
    "    ns = data[\"niveles_series\"]\n",
    "    coord_n, coord_b = data[\"coordenadas_niveles\"], data[\"coordenadas_bombeos\"]\n",
    "    sm_prec, sm_ev = data[\"sm_precip\"], data[\"sm_evap\"]\n",
    "    ALB = data[\"ALB_series\"]\n",
    "    SOP, MOP = data[\"SOP_series\"], data[\"MOP_series\"]\n",
    "    TIL, TUC, PEINE = data[\"TIL_series\"], data[\"TUC_series\"], data[\"PEINE_series\"]\n",
    "    model_stats = {}\n",
    "    gains_data = []\n",
    "    for pozo in location_names:\n",
    "        datos = ns[ns[\"Pozo\"] == pozo][\"Valor\"]\n",
    "        datos.index = pd.to_datetime(datos.index, errors=\"coerce\")\n",
    "        datos = datos.dropna().sort_index().resample(\"D\").mean()\n",
    "        ml = ps.Model(datos, name=f\"{pozo} - {modelo}\")\n",
    "        ml.add_stressmodel(sm_prec)\n",
    "        ml.add_stressmodel(sm_ev)\n",
    "        if modelo == \"Modelo_B\":\n",
    "            sm_alb = ps.StressModel(ALB, ps.Hantush(), name=\"albemarle\", up=False, settings=\"well\")\n",
    "            ml.add_stressmodel(sm_alb)\n",
    "        elif modelo == \"Modelo_C\":\n",
    "            este_pozo = float(coord_n.loc[pozo][\"Este\"])\n",
    "            norte_pozo = float(coord_n.loc[pozo][\"Norte\"])\n",
    "            bombeos, series = [\"alb\", \"til\", \"tuc\", \"peine\"], [ALB, TIL, TUC, PEINE]\n",
    "            dist = [distancia_utm(float(coord_b.loc[b][\"Este\"]), float(coord_b.loc[b][\"Norte\"]), este_pozo, norte_pozo) for b in bombeos]\n",
    "            ml.add_stressmodel(ps.WellModel(series, \"WellModel\", dist))\n",
    "        elif modelo == \"Modelo_D\":\n",
    "            este_pozo = float(coord_n.loc[pozo][\"Este\"])\n",
    "            norte_pozo = float(coord_n.loc[pozo][\"Norte\"])\n",
    "            bombeos, series = [\"sop\", \"mop\"], [SOP, MOP]\n",
    "            dist = [distancia_utm(float(coord_b.loc[b][\"Este\"]), float(coord_b.loc[b][\"Norte\"]), este_pozo, norte_pozo) for b in bombeos]\n",
    "            ml.add_stressmodel(ps.WellModel(series, \"WellModel\", dist))\n",
    "        elif modelo == \"Modelo_E\":\n",
    "            este_pozo = float(coord_n.loc[pozo][\"Este\"])\n",
    "            norte_pozo = float(coord_n.loc[pozo][\"Norte\"])\n",
    "            bombeos = [\"alb\", \"sop\", \"mop\", \"til\", \"tuc\", \"peine\"]\n",
    "            series = [ALB, SOP, MOP, TIL, TUC, PEINE]\n",
    "            dist = [distancia_utm(float(coord_b.loc[b][\"Este\"]), float(coord_b.loc[b][\"Norte\"]), este_pozo, norte_pozo) for b in bombeos]\n",
    "            ml.add_stressmodel(ps.WellModel(series, \"WellModel\", dist))\n",
    "        ml.add_noisemodel(ps.NoiseModel())\n",
    "        ml.solve(report=False)\n",
    "        model_stats[pozo] = calculate_model_statistics(ml)\n",
    "        os.makedirs(modelo, exist_ok=True)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={\"width_ratios\": [4, 1]})\n",
    "        ml.plot(ax=axes[0])\n",
    "        axes[0].set_ylabel(\"Nivel de agua [msnm]\")\n",
    "        axes[0].set_title(f\"{modelo} - {pozo}\")\n",
    "        axes[0].ticklabel_format(axis=\"y\", style=\"plain\", useOffset=False)\n",
    "        axes[1].hist(ml.residuals(), bins=25, edgecolor=\"black\", orientation=\"horizontal\")\n",
    "        axes[1].set_xlabel(\"Frecuencia\")\n",
    "        axes[1].set_ylabel(\"Residuales\")\n",
    "        axes[1].set_title(\"Residuales\")\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(os.path.join(modelo, f\"{modelo}_{pozo}.png\"), dpi=200)\n",
    "        plt.close()\n",
    "        if modelo in [\"Modelo_C\", \"Modelo_D\", \"Modelo_E\"]:\n",
    "            wm = ml.stressmodels[\"WellModel\"]\n",
    "            names = {\"Modelo_C\": [\"alb\", \"til\", \"tuc\", \"peine\"], \"Modelo_D\": [\"sop\", \"mop\"]}.get(modelo, [\"alb\", \"sop\", \"mop\", \"til\", \"tuc\", \"peine\"])\n",
    "            pozo_gains = {\"pozo\": pozo}\n",
    "            for i, name in enumerate(names[: len(wm.stress)]):\n",
    "                p = wm.get_parameters(model=ml, istress=i)\n",
    "                pozo_gains[name] = wm.rfunc.gain(p) * 1e6 / 365.25\n",
    "            gains_data.append(pozo_gains)\n",
    "    return model_stats, gains_data\n",
    "\n",
    "\n",
    "def _run_one_pozo_for_model(modelo: str, pozo: str, bundle: dict):\n",
    "    \"\"\"Wrapper para multiprocessing: un modelo para un pozo. Returns (modelo, model_stats, gains_data).\"\"\"\n",
    "    model_stats, gains_data = create_model_with_data(modelo, [pozo], bundle)\n",
    "    return (modelo, model_stats, gains_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carga y preparación de datos de niveles"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "t_start = time.perf_counter()\n",
    "print(\"=== 3. CARGANDO DATOS DE NIVELES ===\")\n",
    "\n",
    "niveles_path = os.path.join(\"datos\", \"pozos nivel peine\", \"Niveles.csv\")\n",
    "niveles = pd.read_csv(niveles_path, encoding=\"utf-8-sig\")\n",
    "niveles[\"Fecha\"] = pd.to_datetime(niveles[\"Fecha\"], dayfirst=True, errors=\"coerce\")\n",
    "niveles[\"Valor\"] = pd.to_numeric(niveles[\"Valor\"], errors=\"coerce\")\n",
    "niveles[\"Pozo\"] = niveles[\"Pozo\"].astype(str).str.strip()\n",
    "niveles[\"Tipo\"] = niveles[\"Tipo\"].astype(str).str.strip().str.upper()\n",
    "niveles = niveles.dropna(subset=[\"Fecha\", \"Pozo\", \"Tipo\", \"Valor\"]).copy()\n",
    "inicio = pd.Timestamp(\"2000-01-01\")\n",
    "niveles = niveles[niveles[\"Fecha\"] >= inicio].copy()\n",
    "\n",
    "monitoreo_path = os.path.join(\"datos\", \"pozos nivel peine\", \"monitoreo_total.csv\")\n",
    "monitoreo = pd.read_csv(monitoreo_path, encoding=\"utf-8-sig\")\n",
    "allowed = monitoreo[\"Nombre\"].astype(str).str.strip().str.replace(r\"^Pozo\\s+\", \"\", regex=True).dropna().unique()\n",
    "niveles = niveles[niveles[\"Pozo\"].isin(set(allowed))].copy()\n",
    "\n",
    "print(f\"Total de registros de niveles: {len(niveles)}\")\n",
    "print(f\"Pozos únicos: {niveles['Pozo'].nunique()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análisis de tendencias (Mann-Kendall)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=== 4. ANÁLISIS DE TENDENCIAS ===\")\n",
    "\n",
    "exclude_head = {\"PP-03\", \"MP-07C-1\", \"MP-07A\", \"L10-1\", \"PP-01\", \"MP-08A\", \"BA-30\"}\n",
    "mk_head = _mk_table(niveles[(niveles[\"Tipo\"] == \"HEAD\") & (~niveles[\"Pozo\"].isin(exclude_head))])\n",
    "mk_head_excl = _mk_table(niveles[(niveles[\"Tipo\"] == \"HEAD\") & (niveles[\"Pozo\"].isin(exclude_head))])\n",
    "mk_stage = _mk_table(niveles[niveles[\"Tipo\"] == \"STAGE\"])\n",
    "\n",
    "mk_head.to_csv(\"resultados_mann_kendall_head.csv\", index=False, float_format=\"%.3f\")\n",
    "mk_head_excl.to_csv(\"resultados_mann_kendall_head_excluidos.csv\", index=False, float_format=\"%.3f\")\n",
    "mk_stage.to_csv(\"resultados_mann_kendall_limnimetricos.csv\", index=False, float_format=\"%.3f\")\n",
    "\n",
    "print(f\"MK HEAD: {len(mk_head)} pozos\")\n",
    "print(f\"MK HEAD excluidos: {len(mk_head_excl)} pozos\")\n",
    "print(f\"MK STAGE: {len(mk_stage)} pozos\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Carga de datos de estrés (clima y bombeos)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=== 5. CARGANDO DATOS DE ESTRÉS ===\")\n",
    "\n",
    "archivos_precipitacion = [\n",
    "    os.path.join('datos', 'resultados_meteo', 'precip', 'Prec_CHAXA.csv'),\n",
    "    os.path.join('datos', 'resultados_meteo', 'precip', 'Prec_LZA9-1 (Interna).csv'),\n",
    "    os.path.join('datos', 'resultados_meteo', 'precip', 'Prec_LZA10-1.csv')\n",
    "]\n",
    "archivos_evaporacion = [\n",
    "    os.path.join('datos', 'resultados_meteo', 'evap', 'Evap_CHAXA.csv'),\n",
    "    os.path.join('datos', 'resultados_meteo', 'evap', 'Evap_LZA9-1 (Interna).csv')\n",
    "]\n",
    "precipitacion_list = [pd.read_csv(a, index_col=0, parse_dates=True).squeeze(\"columns\") for a in archivos_precipitacion]\n",
    "precipitacion = pd.concat(precipitacion_list).groupby(level=0).mean()\n",
    "evaporacion_list = [pd.read_csv(a, index_col=0, parse_dates=True).squeeze(\"columns\") for a in archivos_evaporacion]\n",
    "evaporacion = pd.concat(evaporacion_list).groupby(level=0).mean()\n",
    "\n",
    "precipitacion.index = pd.to_datetime(precipitacion.index, errors=\"coerce\")\n",
    "precipitacion = precipitacion.dropna().sort_index()\n",
    "evaporacion.index = pd.to_datetime(evaporacion.index, errors=\"coerce\")\n",
    "evaporacion = evaporacion.dropna().sort_index()\n",
    "prec = precipitacion.resample(\"D\").sum()\n",
    "evap = evaporacion.resample(\"D\").mean()\n",
    "\n",
    "coef = 0.225\n",
    "sm_precip = ps.StressModel(prec * coef, ps.Gamma(), settings=\"prec\", name=\"precipitacion\")\n",
    "sm_evap = ps.StressModel(evap, ps.Gamma(), settings=\"evap\", name=\"evaporacion\")\n",
    "\n",
    "ALB_series = load_pumping_data(os.path.join(\"datos\", \"pumping\", \"alb_pump.csv\"))\n",
    "SOP_series = load_pumping_data(os.path.join(\"datos\", \"pumping\", \"SOP_monthly_m3.csv\"))\n",
    "MOP_series = load_pumping_data(os.path.join(\"datos\", \"pumping\", \"MOP_monthly_m3.csv\"))\n",
    "TIL_series = load_pumping_data(os.path.join(\"datos\", \"pumping\", \"tilopozo_pumping.csv\"))\n",
    "TUC_series = load_pumping_data(os.path.join(\"datos\", \"pumping\", \"tucucaro_pumping.csv\"))\n",
    "PEINE_series = load_pumping_data(os.path.join(\"datos\", \"pumping\", \"Pozo_peine_pumping.csv\"))\n",
    "\n",
    "print(\"Datos de estrés cargados correctamente\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Carga de coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=== 6. CARGANDO COORDENADAS ===\")\n",
    "\n",
    "coordenadas_bombeos_path = os.path.join(\"datos\", \"pumping\", \"bombeos_ubicacion.csv\")\n",
    "coordenadas_bombeos = pd.read_csv(coordenadas_bombeos_path, encoding=\"utf-8-sig\")\n",
    "coordenadas_bombeos.set_index(\"Nombre\", inplace=True)\n",
    "\n",
    "coordenadas_niveles_path = os.path.join(\"datos\", \"pozos nivel peine\", \"monitoreo_total.csv\")\n",
    "coordenadas_niveles = pd.read_csv(coordenadas_niveles_path, encoding=\"utf-8-sig\")\n",
    "if \"Nombre\" in coordenadas_niveles.columns:\n",
    "    coordenadas_niveles.set_index(\"Nombre\", inplace=True)\n",
    "else:\n",
    "    col_name = coordenadas_niveles.columns[coordenadas_niveles.columns.str.lower() == \"nombre\"][0]\n",
    "    coordenadas_niveles.set_index(col_name, inplace=True)\n",
    "\n",
    "print(f\"Coordenadas de {len(coordenadas_bombeos)} bombeos cargadas\")\n",
    "print(f\"Coordenadas de {len(coordenadas_niveles)} pozos cargadas\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ejecución: modelos secuencial (A, B, C...), pozos en paralelo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Modelos = [\"Modelo_A\", \"Modelo_B\", \"Modelo_C\", \"Modelo_D\", \"Modelo_E\"]\n",
    "niveles_series = niveles.copy()\n",
    "niveles_series.set_index(\"Fecha\", inplace=True)\n",
    "location_names = sorted(niveles[\"Pozo\"].unique().tolist())\n",
    "bundle = get_data_bundle()\n",
    "\n",
    "total_modelos = 0\n",
    "for modelo in Modelos:\n",
    "    print(f\"\\n--- {modelo} ---\")\n",
    "    if N_WORKERS <= 1:\n",
    "        results = []\n",
    "        for pozo in location_names:\n",
    "            results.append(_run_one_pozo_for_model(modelo, pozo, bundle))\n",
    "    else:\n",
    "        with Pool(N_WORKERS) as pool:\n",
    "            results = pool.starmap(_run_one_pozo_for_model, [(modelo, pozo, bundle) for pozo in location_names])\n",
    "    model_stats = {}\n",
    "    gains_data = []\n",
    "    for (m, stats, gains) in results:\n",
    "        model_stats.update(stats)\n",
    "        gains_data.extend(gains)\n",
    "    total_modelos += len(model_stats)\n",
    "    df_stats = pd.DataFrame.from_dict(model_stats, orient=\"index\")\n",
    "    df_stats[\"IVM\"] = df_stats.apply(calculate_ivm, axis=1)\n",
    "    summary_row = pd.DataFrame([{c: \"\" for c in df_stats.columns}], index=[\"Summary\"])\n",
    "    summary_row[\"IVM\"] = f\"Total Válidos: {(df_stats['IVM'] == 'Válido').sum()}\"\n",
    "    df_stats = pd.concat([df_stats, summary_row])\n",
    "    df_stats.to_csv(f\"Summary_{modelo}.csv\")\n",
    "    print(f\"  Guardado: Summary_{modelo}.csv\")\n",
    "    if modelo in [\"Modelo_C\", \"Modelo_D\", \"Modelo_E\"] and gains_data:\n",
    "        df_gains = pd.DataFrame(gains_data).set_index(\"pozo\")\n",
    "        df_gains = pd.concat([df_gains, pd.DataFrame([df_gains.mean()], index=[\"mean\"])])\n",
    "        df_gains.to_csv(f\"{modelo}_gains_by_pozo.csv\")\n",
    "        print(f\"  Guardado: {modelo}_gains_by_pozo.csv\")\n",
    "\n",
    "elapsed = time.perf_counter() - t_start\n",
    "print(\"\\n=== PROCESO COMPLETADO ===\")\n",
    "print(f\"Total de modelos creados: {total_modelos}\")\n",
    "if elapsed >= 60:\n",
    "    print(f\"Tiempo total: {int(elapsed // 60)}m {elapsed % 60:.1f}s\")\n",
    "else:\n",
    "    print(f\"Tiempo total: {elapsed:.1f}s\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
